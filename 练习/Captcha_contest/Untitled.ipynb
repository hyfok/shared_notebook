{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, '1.14.0', '2.2.4')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "#import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "import keras\n",
    "#from tensorflow.keras import layers\n",
    "from keras import layers\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available(),tf.__version__,keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:\\\\Study\\\\Anaconda\\\\envs\\\\keras-gpu\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\keras\\\\api\\\\_v1',\n",
       " 'E:\\\\Study\\\\Anaconda\\\\envs\\\\keras-gpu\\\\lib\\\\site-packages\\\\tensorflow_estimator\\\\python\\\\estimator\\\\api\\\\_v1',\n",
       " 'E:\\\\Study\\\\Anaconda\\\\envs\\\\keras-gpu\\\\lib\\\\site-packages\\\\tensorflow',\n",
       " 'E:\\\\Study\\\\Anaconda\\\\envs\\\\keras-gpu\\\\lib\\\\site-packages\\\\tensorflow\\\\_api\\\\v1']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__path__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mm = np.array(Image.open('E:\\\\Study\\\\竞赛\\\\识别验证码\\\\train\\\\1.jpg'))\n",
    "mm =np.swapaxes(pp,1,2)\n",
    "mm = mm.reshape(1,4,30,40,3)\n",
    "mm =np.swapaxes(mm,2,3)\n",
    "Image.fromarray(mm[0,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'E:\\Study\\竞赛\\识别验证码'\n",
    "#base_path = '/home/hyfok/Notebook/Captcha_contest/data'\n",
    "\n",
    "def read_images(root=base_path, train=True):\n",
    "    def fun(i):\n",
    "        if ord(i)< 65:\n",
    "            return ord(i)- 48\n",
    "        elif ord(i)>=97:\n",
    "            return ord(i)-71+10 \n",
    "        else:\n",
    "            return ord(i) - 65 + 10 \n",
    "    csv_fname = os.path.join(root, 'train/train_label.csv')\n",
    "    csv_data = pd.read_csv(csv_fname, usecols=['ID', 'label'])\n",
    "    images,labels = csv_data.to_numpy()[:,0].tolist(),csv_data.to_numpy()[:,1].tolist()\n",
    "    images = [os.path.join(root, 'train/'+i) for i in images]\n",
    "    images = np.array([np.array(Image.open(os.path.join(base_path, i))) for i in images])\n",
    "    labels = np.array([[fun(i) for i in i] for i in labels])\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = read_images() #5000 * 40 * 120 * 3 ;  5000 * 4 \n",
    "labels = np.array([tf.keras.utils.to_categorical(i, 62) for i in labels]) #5000 * 4 * 62\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, labels = read_images()\n",
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(40, 120, 3), name='img')\n",
    "\n",
    "h1 = layers.Conv2D(32, 3, activation='relu', padding='same',strides=1, kernel_initializer='glorot_normal',use_bias=False)(inputs)\n",
    "h1 = layers.BatchNormalization()(h1)\n",
    "h1 = layers.Conv2D(64, 3, activation='relu', strides=2, padding='same', kernel_initializer='glorot_normal',use_bias=False)(h1)\n",
    "block1_out = layers.BatchNormalization()(h1)\n",
    "#block1_out = layers.MaxPooling2D(2)(h1) # N * 20 * 60 * 64\n",
    "\n",
    "h2 = layers.Conv2D(64, 3, activation='relu', padding='same',kernel_initializer='glorot_normal',use_bias=False)(block1_out)\n",
    "h2 = layers.BatchNormalization()(h2)\n",
    "h2 = layers.Conv2D(64, 3, activation='relu', padding='same',kernel_initializer='glorot_normal',use_bias=False)(h2)\n",
    "h2 = layers.BatchNormalization()(h2)\n",
    "block2_out = layers.ReLU()(layers.add([h2, block1_out])) # N * 20 * 60 * 64\n",
    "\n",
    "h3 = layers.Conv2D(64, 3, activation='relu',strides=2, padding='same',kernel_initializer='glorot_normal',use_bias=False)(block2_out)\n",
    "h3 = layers.BatchNormalization()(h3)\n",
    "#h3 = layers.MaxPooling2D(2)(h3)  \n",
    "h3 = layers.Conv2D(64, 3, activation='relu', padding='same',kernel_initializer='glorot_normal',use_bias=False)(h3)\n",
    "h3 = layers.BatchNormalization()(h3)\n",
    "block2_out = layers.Conv2D(64, 1, activation='relu', padding='same',strides=2,kernel_initializer='glorot_normal',use_bias=False)(block2_out)\n",
    "block3_out = layers.ReLU()(layers.add([h3, block2_out])) # N * 10 * 30 * 64\n",
    "\n",
    "h4 = layers.Conv2D(64, 3, activation='relu', padding='same',kernel_initializer='glorot_normal',use_bias=False)(block3_out)\n",
    "h4 = layers.BatchNormalization()(h4)\n",
    "h4 = layers.Conv2D(64, 3, activation='relu', padding='same',kernel_initializer='glorot_normal',use_bias=False)(h4)\n",
    "h4 = layers.BatchNormalization()(h4)\n",
    "block4_out = layers.ReLU()(layers.add([h4, block3_out])) # N * 10 * 30 * 64\n",
    "\n",
    "h5 = layers.convolutional.ZeroPadding2D(padding=(2, 2), data_format=None)(block4_out)\n",
    "#h5 = layers.convolutional.ZeroPadding2D(padding=(2, 2), data_format=None)(block3_out)\n",
    "h5 = layers.Conv2D(128, 3, activation='relu',strides=2, padding='valid',kernel_initializer='glorot_normal',use_bias=False)(h5)\n",
    "h5 = layers.BatchNormalization()(h5)\n",
    "#h5 = layers.MaxPooling2D(2)(h5)\n",
    "h5 = layers.Conv2D(128, 3, activation='relu',padding='same',kernel_initializer='glorot_normal',use_bias=False)(h5) \n",
    "h5 = layers.BatchNormalization()(h5)\n",
    "block4_out = layers.convolutional.ZeroPadding2D(padding=(1, 1), data_format=None)(block4_out)\n",
    "#block4_out = layers.convolutional.ZeroPadding2D(padding=(1, 1), data_format=None)(block3_out)\n",
    "block4_out = layers.Conv2D(128, 1, activation='relu', padding='same',strides=2,kernel_initializer='glorot_normal',use_bias=False)(block4_out)\n",
    "block5_out = layers.ReLU()(layers.add([h5, block4_out])) # N * 6 * 16 * 128\n",
    "\n",
    "h6 = layers.Conv2D(256, 3, activation='relu',padding='same',kernel_initializer='glorot_normal',use_bias=False)(block5_out)\n",
    "h6 = layers.BatchNormalization()(h6)\n",
    "h6 = layers.Conv2D(256, 3, activation='relu',padding='same',kernel_initializer='glorot_normal',use_bias=False)(h6) \n",
    "h6 = layers.BatchNormalization()(h6)\n",
    "block5_out = layers.Conv2D(256, 1, activation='relu', padding='same',strides=1,kernel_initializer='glorot_normal',use_bias=False)(block5_out)\n",
    "block6_out = layers.ReLU()(layers.add([h6, block5_out]))# N * 6 * 16 * 256\n",
    "\n",
    "#out = layers.Flatten()(block6_out)\n",
    "#out = layers.Dense(62*4, activation='linear', name='fc1')(out)\n",
    "#out = layers.Reshape((4,62))(out)\n",
    "\n",
    "out = keras.layers.Lambda(lambda x:keras.backend.permute_dimensions(x,(0,2,1,3)))(block6_out)\n",
    "out = layers.Reshape((4,6,4,256))(out)\n",
    "out = keras.layers.Lambda(lambda x:keras.backend.permute_dimensions(x,(0,1,3,2,4)))(out)\n",
    "out = layers.TimeDistributed(layers.Conv2D(256, 3, activation='relu',padding='same', strides=1,kernel_initializer='glorot_normal',use_bias=False))(out)\n",
    "out = layers.TimeDistributed(layers.BatchNormalization())(out)\n",
    "out = layers.TimeDistributed(layers.Conv2D(256, 1, activation='relu',padding='same', strides=1,kernel_initializer='glorot_normal',use_bias=False))(out)\n",
    "out = layers.Reshape((4,4*6*256))(out)\n",
    "out = layers.TimeDistributed(layers.Dense(256, activation='relu', name='fc1'))(out) # N * 4 * 256\n",
    "out = layers.TimeDistributed(layers.Dropout(0.5))(out)\n",
    "out = layers.TimeDistributed(layers.Dense(62, activation='linear', name='dense_class'))(out)  # N * 4 * 62\n",
    "\n",
    "model = keras.Model(inputs,out)\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "out = keras.layers.Lambda(lambda x:keras.backend.permute_dimensions(x,(0,2,1,3)))(block6_out)\n",
    "out = layers.Reshape((4,6,4,256))(out)\n",
    "out = keras.layers.Lambda(lambda x:keras.backend.permute_dimensions(x,(0,1,3,2,4)))(out)\n",
    "out = layers.TimeDistributed(layers.Conv2D(256, 1, activation='relu', strides=1,kernel_initializer='glorot_normal',use_bias=False))(out)\n",
    "out = layers.Reshape((4,4*6*256))(out)\n",
    "out = layers.TimeDistributed(layers.Dense(256, activation='relu', name='fc1'))(out) # N * 4 * 256\n",
    "out = layers.TimeDistributed(layers.Dropout(0.5))(out)\n",
    "out = layers.TimeDistributed(layers.Dense(62, activation='linear', name='dense_class'))(out)  # N * 4 * 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img (InputLayer)                (None, 40, 120, 3)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 40, 120, 32)  864         img[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 40, 120, 32)  128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 20, 60, 64)   18432       batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 20, 60, 64)   256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 20, 60, 64)   36864       batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 20, 60, 64)   256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 20, 60, 64)   36864       batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 20, 60, 64)   256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 20, 60, 64)   0           batch_normalization_16[0][0]     \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 20, 60, 64)   0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 10, 30, 64)   36864       re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 10, 30, 64)   256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 10, 30, 64)   36864       batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 10, 30, 64)   256         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 10, 30, 64)   4096        re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 10, 30, 64)   0           batch_normalization_18[0][0]     \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 10, 30, 64)   0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 10, 30, 64)   36864       re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 10, 30, 64)   256         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 10, 30, 64)   36864       batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 10, 30, 64)   256         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 10, 30, 64)   0           batch_normalization_20[0][0]     \n",
      "                                                                 re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 10, 30, 64)   0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 14, 34, 64)   0           re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 6, 16, 128)   73728       zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 6, 16, 128)   512         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 6, 16, 128)   147456      batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 12, 32, 64)   0           re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 6, 16, 128)   512         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 6, 16, 128)   8192        zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 6, 16, 128)   0           batch_normalization_22[0][0]     \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 6, 16, 128)   0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 6, 16, 256)   294912      re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 6, 16, 256)   1024        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 6, 16, 256)   589824      batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 6, 16, 256)   1024        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 6, 16, 256)   32768       re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 6, 16, 256)   0           batch_normalization_24[0][0]     \n",
      "                                                                 conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 6, 16, 256)   0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 16, 6, 256)   0           re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 4, 6, 4, 256) 0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 4, 4, 6, 256) 0           reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 4, 4, 6, 256) 65536       lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 4, 6144)      0           time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 4, 256)       1573120     reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 4, 256)       0           time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, 4, 62)        15934       time_distributed_7[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 3,051,038\n",
      "Trainable params: 3,048,542\n",
      "Non-trainable params: 2,496\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_sparse_crossentropy(y_true, y_pred):\n",
    "    y_pred = K.reshape(y_pred, (-1, K.int_shape(y_pred)[-1]))\n",
    "    log_softmax = tf.nn.log_softmax(y_pred)\n",
    "\n",
    "    #y_true = K.one_hot(tf.to_int32(K.flatten(y_true)), K.int_shape(y_pred)[-1]+1)\n",
    "    #unpacked = tf.unstack(y_true, axis=-1)\n",
    "    #y_true = tf.stack(unpacked[:-1], axis=-1)\n",
    "    y_true = K.reshape(y_true, (-1, K.int_shape(y_pred)[-1]))\n",
    "    cross_entropy = -K.sum(y_true * log_softmax, axis=1)\n",
    "    cross_entropy_mean = K.mean(cross_entropy)\n",
    "\n",
    "    return cross_entropy_mean\n",
    "\n",
    "def sparse_accuracy(y_true, y_pred):\n",
    "   \n",
    "    nb_classes = K.int_shape(y_pred)[-1]\n",
    "    \n",
    "    return K.sum(tf.to_float( tf.reduce_all((K.equal(K.argmax(y_true, axis=-1), K.argmax(y_pred, axis=-1))),axis=1)))/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr=0.001)\n",
    "model.compile(optimizer=optimizer,\n",
    "             loss=softmax_sparse_crossentropy,\n",
    "             metrics=[sparse_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/30\n",
      "4500/4500 [==============================] - 85s 19ms/step - loss: 4.2095 - sparse_accuracy: 0.0000e+00 - val_loss: 4.2530 - val_sparse_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 4.1420 - sparse_accuracy: 0.0000e+00 - val_loss: 4.3786 - val_sparse_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 4.1282 - sparse_accuracy: 0.0000e+00 - val_loss: 4.6157 - val_sparse_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 3.5946 - sparse_accuracy: 0.0000e+00 - val_loss: 3.0961 - val_sparse_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 2.0774 - sparse_accuracy: 0.0291 - val_loss: 1.5034 - val_sparse_accuracy: 0.1380\n",
      "Epoch 6/30\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 1.0843 - sparse_accuracy: 0.1973 - val_loss: 0.5126 - val_sparse_accuracy: 0.5940\n",
      "Epoch 7/30\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.6669 - sparse_accuracy: 0.4189 - val_loss: 0.3764 - val_sparse_accuracy: 0.6620\n",
      "Epoch 8/30\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.4229 - sparse_accuracy: 0.5907 - val_loss: 0.3710 - val_sparse_accuracy: 0.6740\n",
      "Epoch 9/30\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.2765 - sparse_accuracy: 0.7189 - val_loss: 0.2832 - val_sparse_accuracy: 0.7860\n",
      "Epoch 10/30\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.1997 - sparse_accuracy: 0.8073 - val_loss: 0.1775 - val_sparse_accuracy: 0.8820\n",
      "Epoch 11/30\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.1450 - sparse_accuracy: 0.8580 - val_loss: 0.1606 - val_sparse_accuracy: 0.8820\n",
      "Epoch 12/30\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.1179 - sparse_accuracy: 0.8882 - val_loss: 0.6149 - val_sparse_accuracy: 0.7860\n",
      "Epoch 13/30\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.0995 - sparse_accuracy: 0.9078 - val_loss: 0.1196 - val_sparse_accuracy: 0.9180\n",
      "Epoch 14/30\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.0885 - sparse_accuracy: 0.9151 - val_loss: 0.1887 - val_sparse_accuracy: 0.8740\n",
      "Epoch 15/30\n",
      "4500/4500 [==============================] - 71s 16ms/step - loss: 0.0785 - sparse_accuracy: 0.9320 - val_loss: 0.1783 - val_sparse_accuracy: 0.9180\n",
      "Epoch 16/30\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.0806 - sparse_accuracy: 0.9271 - val_loss: 0.1125 - val_sparse_accuracy: 0.9280\n",
      "Epoch 17/30\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.0716 - sparse_accuracy: 0.9396 - val_loss: 0.1186 - val_sparse_accuracy: 0.9220\n",
      "Epoch 18/30\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.0692 - sparse_accuracy: 0.9436 - val_loss: 0.1066 - val_sparse_accuracy: 0.9220\n",
      "Epoch 19/30\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.0600 - sparse_accuracy: 0.9498 - val_loss: 0.1882 - val_sparse_accuracy: 0.9040\n",
      "Epoch 20/30\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.0547 - sparse_accuracy: 0.9520 - val_loss: 0.1231 - val_sparse_accuracy: 0.9180\n",
      "Epoch 21/30\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.0578 - sparse_accuracy: 0.9547 - val_loss: 0.0888 - val_sparse_accuracy: 0.9320\n",
      "Epoch 22/30\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.0561 - sparse_accuracy: 0.9553 - val_loss: 0.1623 - val_sparse_accuracy: 0.9100\n",
      "Epoch 23/30\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.0481 - sparse_accuracy: 0.9631 - val_loss: 0.1294 - val_sparse_accuracy: 0.9320\n",
      "Epoch 24/30\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.0486 - sparse_accuracy: 0.9611 - val_loss: 0.1484 - val_sparse_accuracy: 0.9440\n",
      "Epoch 25/30\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.0531 - sparse_accuracy: 0.9596 - val_loss: 0.1155 - val_sparse_accuracy: 0.9400\n",
      "Epoch 26/30\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.0490 - sparse_accuracy: 0.9611 - val_loss: 0.2209 - val_sparse_accuracy: 0.9080\n",
      "Epoch 27/30\n",
      "4500/4500 [==============================] - 73s 16ms/step - loss: 0.0490 - sparse_accuracy: 0.9622 - val_loss: 0.1163 - val_sparse_accuracy: 0.9440\n",
      "Epoch 28/30\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.0492 - sparse_accuracy: 0.9600 - val_loss: 0.1513 - val_sparse_accuracy: 0.9160\n",
      "Epoch 29/30\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.0516 - sparse_accuracy: 0.9620 - val_loss: 0.1424 - val_sparse_accuracy: 0.9380\n",
      "Epoch 30/30\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.0509 - sparse_accuracy: 0.9687 - val_loss: 0.1353 - val_sparse_accuracy: 0.9380\n"
     ]
    }
   ],
   "source": [
    "history_n = model.fit(images, labels.reshape(5000,4,62) , epochs=30, batch_size=20, validation_split=0.1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 + 1 30 epoches lr=0.001\n",
    "    loss: 0.0097 - sparse_accuracy: 0.9927 - val_loss: 0.2330 - val_sparse_accuracy: 0.9240\n",
    "# 5 + 1 30 epoches lr=0.001\n",
    "    loss: 0.0082 - sparse_accuracy: 0.9940 - val_loss: 0.1869 - val_sparse_accuracy: 0.9180\n",
    "# 6 + 0 30 epoches lr=0.001\n",
    "    loss: 4.8120e-05 - sparse_accuracy: 0.9998 - val_loss: 0.5913 - val_sparse_accuracy: 0.8360\n",
    "# 7 + 1 30 epoches lr=0.01\n",
    "    0\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "x = tf.constant(1)\n",
    "with tf.Session() as sess:\n",
    "    print sess.run(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.978"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.predict(images[:500])\n",
    "np.equal(result.argmax(axis = -1),labels[:500].argmax(axis = -1)).all(axis=1).sum()/result.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test = np.array([np.array(Image.open(os.path.join(base_path, 'test/%d.jpg'%(i+1)))) for i in range(5000)])\n",
    "result_test = model.predict(images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(x): # 5000 * 4 numpy\n",
    "    data = x.tolist()\n",
    "    def fun(i):\n",
    "        if i< 10:\n",
    "            return chr(i+48)\n",
    "        elif i>=36:\n",
    "            return chr(i+71-10) \n",
    "        else:\n",
    "            return chr(i+65-10)\n",
    "    data = [''.join([fun(i) for i in i]) for i in data]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_csv = decoder(result_test.argmax(axis = -1))\n",
    "pd.DataFrame.from_dict({'ID': ['%d.jpg'%(i+1) for i in range(5000)], 'label': to_csv}).to_csv('hfy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

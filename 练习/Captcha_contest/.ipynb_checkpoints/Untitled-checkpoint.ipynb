{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, '1.14.0', '2.2.4')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "#import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "import keras\n",
    "#from tensorflow.keras import layers\n",
    "from keras import layers\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available(),tf.__version__,keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/hyfok/anaconda3/envs/keras-gpu/lib/python3.7/site-packages/tensorflow/python/keras/api/_v1',\n",
       " '/home/hyfok/anaconda3/envs/keras-gpu/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/api/_v1',\n",
       " '/home/hyfok/anaconda3/envs/keras-gpu/lib/python3.7/site-packages/tensorflow',\n",
       " '/home/hyfok/anaconda3/envs/keras-gpu/lib/python3.7/site-packages/tensorflow/_api/v1']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__path__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mm = np.array(Image.open('E:\\\\Study\\\\竞赛\\\\识别验证码\\\\train\\\\1.jpg'))\n",
    "mm =np.swapaxes(pp,1,2)\n",
    "mm = mm.reshape(1,4,30,40,3)\n",
    "mm =np.swapaxes(mm,2,3)\n",
    "Image.fromarray(mm[0,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_path = 'E:\\Study\\竞赛\\识别验证码'\n",
    "base_path = '/home/hyfok/Notebook/Captcha_contest/data'\n",
    "\n",
    "def read_images(root=base_path, train=True):\n",
    "    def fun(i):\n",
    "        if ord(i)< 65:\n",
    "            return ord(i)- 48\n",
    "        elif ord(i)>=97:\n",
    "            return ord(i)-71+10 \n",
    "        else:\n",
    "            return ord(i) - 65 + 10 \n",
    "    csv_fname = os.path.join(root, 'train/train_label.csv')\n",
    "    csv_data = pd.read_csv(csv_fname, usecols=['ID', 'label'])\n",
    "    images,labels = csv_data.to_numpy()[:,0].tolist(),csv_data.to_numpy()[:,1].tolist()\n",
    "    images = [os.path.join(root, 'train/'+i) for i in images]\n",
    "    images = np.array([np.array(Image.open(os.path.join(base_path, i))) for i in images])\n",
    "    labels = np.array([[fun(i) for i in i] for i in labels])\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = read_images() #5000 * 40 * 120 * 3 ;  5000 * 4 \n",
    "labels = np.array([tf.keras.utils.to_categorical(i, 62) for i in labels]) #5000 * 4 * 62\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, labels = read_images()\n",
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(40, 120, 3), name='img')\n",
    "\n",
    "h1 = layers.Conv2D(32, 3, activation='relu', padding='same',strides=1, kernel_initializer='glorot_normal',use_bias=False)(inputs)\n",
    "h1 = layers.BatchNormalization()(h1)\n",
    "h1 = layers.Conv2D(64, 3, activation='relu', strides=2, padding='same', kernel_initializer='glorot_normal',use_bias=False)(h1)\n",
    "block1_out = layers.BatchNormalization()(h1)\n",
    "#block1_out = layers.MaxPooling2D(2)(h1) # N * 20 * 60 * 64\n",
    "\n",
    "h2 = layers.Conv2D(64, 3, activation='relu', padding='same',kernel_initializer='glorot_normal',use_bias=False)(block1_out)\n",
    "h2 = layers.BatchNormalization()(h2)\n",
    "h2 = layers.Conv2D(64, 3, activation='relu', padding='same',kernel_initializer='glorot_normal',use_bias=False)(h2)\n",
    "h2 = layers.BatchNormalization()(h2)\n",
    "block2_out = layers.ReLU()(layers.add([h2, block1_out])) # N * 20 * 60 * 64\n",
    "\n",
    "h3 = layers.Conv2D(64, 3, activation='relu',strides=2, padding='same',kernel_initializer='glorot_normal',use_bias=False)(block2_out)\n",
    "h3 = layers.BatchNormalization()(h3)\n",
    "#h3 = layers.MaxPooling2D(2)(h3)  \n",
    "h3 = layers.Conv2D(64, 3, activation='relu', padding='same',kernel_initializer='glorot_normal',use_bias=False)(h3)\n",
    "h3 = layers.BatchNormalization()(h3)\n",
    "block2_out = layers.Conv2D(64, 1, activation='relu', padding='same',strides=2,kernel_initializer='glorot_normal',use_bias=False)(block2_out)\n",
    "block3_out = layers.ReLU()(layers.add([h3, block2_out])) # N * 10 * 30 * 64\n",
    "\n",
    "h4 = layers.Conv2D(64, 3, activation='relu', padding='same',kernel_initializer='glorot_normal',use_bias=False)(block3_out)\n",
    "h4 = layers.BatchNormalization()(h4)\n",
    "h4 = layers.Conv2D(64, 3, activation='relu', padding='same',kernel_initializer='glorot_normal',use_bias=False)(h4)\n",
    "h4 = layers.BatchNormalization()(h4)\n",
    "block4_out = layers.ReLU()(layers.add([h4, block3_out])) # N * 10 * 30 * 64\n",
    "\n",
    "h5 = layers.convolutional.ZeroPadding2D(padding=(2, 2), data_format=None)(block4_out)\n",
    "h5 = layers.Conv2D(128, 3, activation='relu',strides=2, padding='valid',kernel_initializer='glorot_normal',use_bias=False)(h5)\n",
    "h5 = layers.BatchNormalization()(h5)\n",
    "#h5 = layers.MaxPooling2D(2)(h5)\n",
    "h5 = layers.Conv2D(128, 3, activation='relu',padding='same',kernel_initializer='glorot_normal',use_bias=False)(h5) \n",
    "h5 = layers.BatchNormalization()(h5)\n",
    "block4_out = layers.convolutional.ZeroPadding2D(padding=(1, 1), data_format=None)(block4_out)\n",
    "block4_out = layers.Conv2D(128, 1, activation='relu', padding='same',strides=2,kernel_initializer='glorot_normal',use_bias=False)(block4_out)\n",
    "block5_out = layers.ReLU()(layers.add([h5, block4_out])) # N * 6 * 16 * 128\n",
    "\n",
    "h6 = layers.Conv2D(256, 3, activation='relu',padding='same',kernel_initializer='glorot_normal',use_bias=False)(block5_out)\n",
    "h6 = layers.BatchNormalization()(h6)\n",
    "h6 = layers.Conv2D(256, 3, activation='relu',padding='same',kernel_initializer='glorot_normal',use_bias=False)(h6) \n",
    "h6 = layers.BatchNormalization()(h6)\n",
    "block5_out = layers.Conv2D(256, 1, activation='relu', padding='same',strides=1,kernel_initializer='glorot_normal',use_bias=False)(block5_out)\n",
    "block6_out = layers.ReLU()(layers.add([h6, block5_out]))# N * 6 * 16 * 128\n",
    "\n",
    "#out = layers.Flatten()(block6_out)\n",
    "#out = layers.Dense(62*4, activation='linear', name='fc1')(out)\n",
    "#out = layers.Reshape((4,62))(out)\n",
    "\n",
    "out = keras.layers.Lambda(lambda x:keras.backend.permute_dimensions(x,(0,2,1,3)))(block6_out)\n",
    "out = layers.Reshape((4,6,4,256))(out)\n",
    "out = keras.layers.Lambda(lambda x:keras.backend.permute_dimensions(x,(0,1,3,2,4)))(out)\n",
    "out = layers.TimeDistributed(layers.Conv2D(256, 1, activation='relu', strides=1,kernel_initializer='glorot_normal',use_bias=False))(out)\n",
    "out = layers.Reshape((4,4*6*256))(out)\n",
    "out = layers.TimeDistributed(layers.Dense(256, activation='relu', name='fc1'))(out) # N * 4 * 256\n",
    "out = layers.TimeDistributed(layers.Dropout(0.5))(out)\n",
    "out = layers.TimeDistributed(layers.Dense(62, activation='linear', name='dense_class'))(out)  # N * 4 * 64\n",
    "\n",
    "model = keras.Model(inputs,out)\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "out = keras.layers.Lambda(lambda x:keras.backend.permute_dimensions(x,(0,2,1,3)))(block6_out)\n",
    "out = layers.Reshape((4,6,4,256))(out)\n",
    "out = keras.layers.Lambda(lambda x:keras.backend.permute_dimensions(x,(0,1,3,2,4)))(out)\n",
    "out = layers.TimeDistributed(layers.Conv2D(256, 1, activation='relu', strides=1,kernel_initializer='glorot_normal',use_bias=False))(out)\n",
    "out = layers.Reshape((4,4*6*256))(out)\n",
    "out = layers.TimeDistributed(layers.Dense(256, activation='relu', name='fc1'))(out) # N * 4 * 256\n",
    "out = layers.TimeDistributed(layers.Dropout(0.5))(out)\n",
    "out = layers.TimeDistributed(layers.Dense(62, activation='linear', name='dense_class'))(out)  # N * 4 * 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img (InputLayer)                (None, 40, 120, 3)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 40, 120, 32)  864         img[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 40, 120, 32)  128         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 20, 60, 64)   18432       batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 20, 60, 64)   256         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 20, 60, 64)   36864       batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 20, 60, 64)   256         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 20, 60, 64)   36864       batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 20, 60, 64)   256         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 20, 60, 64)   0           batch_normalization_40[0][0]     \n",
      "                                                                 batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_16 (ReLU)                 (None, 20, 60, 64)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 10, 30, 64)   36864       re_lu_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 10, 30, 64)   256         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 10, 30, 64)   36864       batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 10, 30, 64)   256         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 10, 30, 64)   4096        re_lu_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 10, 30, 64)   0           batch_normalization_42[0][0]     \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_17 (ReLU)                 (None, 10, 30, 64)   0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 10, 30, 64)   36864       re_lu_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 10, 30, 64)   256         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 10, 30, 64)   36864       batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 10, 30, 64)   256         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 10, 30, 64)   0           batch_normalization_44[0][0]     \n",
      "                                                                 re_lu_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_18 (ReLU)                 (None, 10, 30, 64)   0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPadding2D (None, 14, 34, 64)   0           re_lu_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 6, 16, 128)   73728       zero_padding2d_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 6, 16, 128)   512         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 6, 16, 128)   147456      batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPadding2D (None, 12, 32, 64)   0           re_lu_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 6, 16, 128)   512         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 6, 16, 128)   8192        zero_padding2d_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 6, 16, 128)   0           batch_normalization_46[0][0]     \n",
      "                                                                 conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_19 (ReLU)                 (None, 6, 16, 128)   0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 6, 16, 256)   294912      re_lu_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 6, 16, 256)   1024        conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 6, 16, 256)   589824      batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 6, 16, 256)   1024        conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 6, 16, 256)   32768       re_lu_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 6, 16, 256)   0           batch_normalization_48[0][0]     \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_20 (ReLU)                 (None, 6, 16, 256)   0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 16, 6, 256)   0           re_lu_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 4, 6, 4, 256) 0           lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 4, 4, 6, 256) 0           reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_13 (TimeDistri (None, 4, 4, 6, 256) 65536       lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 4, 6144)      0           time_distributed_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_14 (TimeDistri (None, 4, 256)       1573120     reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_15 (TimeDistri (None, 4, 256)       0           time_distributed_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_16 (TimeDistri (None, 4, 62)        15934       time_distributed_15[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 3,051,038\n",
      "Trainable params: 3,048,542\n",
      "Non-trainable params: 2,496\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 4, 62)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_sparse_crossentropy(y_true, y_pred):\n",
    "    y_pred = K.reshape(y_pred, (-1, K.int_shape(y_pred)[-1]))\n",
    "    log_softmax = tf.nn.log_softmax(y_pred)\n",
    "\n",
    "    #y_true = K.one_hot(tf.to_int32(K.flatten(y_true)), K.int_shape(y_pred)[-1]+1)\n",
    "    #unpacked = tf.unstack(y_true, axis=-1)\n",
    "    #y_true = tf.stack(unpacked[:-1], axis=-1)\n",
    "    y_true = K.reshape(y_true, (-1, K.int_shape(y_pred)[-1]))\n",
    "    cross_entropy = -K.sum(y_true * log_softmax, axis=1)\n",
    "    cross_entropy_mean = K.mean(cross_entropy)\n",
    "\n",
    "    return cross_entropy_mean\n",
    "\n",
    "def sparse_accuracy(y_true, y_pred):\n",
    "   \n",
    "    nb_classes = K.int_shape(y_pred)[-1]\n",
    "\n",
    "    return K.sum(tf.to_float( K.equal(K.argmax(y_true, axis=-1), K.argmax(y_pred, axis=-1)))) / (4 * K.sum(tf.to_float(nb_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'truediv_1:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type(tf.convert_to_tensor(labels))\n",
    "sparse_accuracy(tf.convert_to_tensor(labels),tf.convert_to_tensor(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr=0.001)\n",
    "model.compile(optimizer=optimizer,\n",
    "             loss=softmax_sparse_crossentropy,\n",
    "             metrics=[sparse_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "4000/4000 [==============================] - 17s 4ms/step - loss: 4.1954 - sparse_accuracy: 0.0156 - val_loss: 19.5335 - val_sparse_accuracy: 0.0143\n",
      "Epoch 2/5\n",
      "4000/4000 [==============================] - 11s 3ms/step - loss: 3.7581 - sparse_accuracy: 0.0736 - val_loss: 2.4766 - val_sparse_accuracy: 0.3210\n",
      "Epoch 3/5\n",
      "4000/4000 [==============================] - 11s 3ms/step - loss: 1.1359 - sparse_accuracy: 0.6629 - val_loss: 0.4677 - val_sparse_accuracy: 0.8600\n",
      "Epoch 4/5\n",
      "4000/4000 [==============================] - 11s 3ms/step - loss: 0.3004 - sparse_accuracy: 0.9131 - val_loss: 0.2395 - val_sparse_accuracy: 0.9353\n",
      "Epoch 5/5\n",
      "4000/4000 [==============================] - 11s 3ms/step - loss: 0.1652 - sparse_accuracy: 0.9541 - val_loss: 0.1691 - val_sparse_accuracy: 0.9610\n"
     ]
    }
   ],
   "source": [
    "history_n = model.fit(images, labels.reshape(5000,4,62) , epochs=5, batch_size=20, validation_split=0.2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = model.predict(images[500].reshape(1,40,120,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39, 49, 41,  2]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr.argmax(axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([39, 49, 41,  2])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[500].argmax(axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 4)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.argmax(axis = -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9718"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.equal(result.argmax(axis = -1),labels.argmax(axis = -1)).sum()/20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test = np.array([np.array(Image.open(os.path.join(base_path, 'test/%d.jpg'%(i+1)))) for i in range(5000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = model.predict(images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[54,  1, 24,  2],\n",
       "       [34, 44, 31, 21],\n",
       "       [51, 12, 22,  6],\n",
       "       ...,\n",
       "       [42, 12, 26, 30],\n",
       "       [28,  0, 20, 46],\n",
       "       [44,  1,  6,  9]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_test.argmax(axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(x): # 5000 * 4 numpy\n",
    "    data = x.tolist()\n",
    "    def fun(i):\n",
    "        if i< 10:\n",
    "            return chr(i+48)\n",
    "        elif i>=36:\n",
    "            return chr(i+71-10) \n",
    "        else:\n",
    "            return chr(i+65-10)\n",
    "    data = [''.join([fun(i) for i in i]) for i in data]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_csv = decoder(result_test.argmax(axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s1O2'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_csv[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict({'A': ['%d.jpg'%(i+1) for i in range(5000)], 'B': to_csv}).to_csv('hfy.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
